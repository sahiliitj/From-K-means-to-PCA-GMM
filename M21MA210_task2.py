# -*- coding: utf-8 -*-
"""Task 2 Assignment 2 ML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XgKzS8CLidb-4eHtrv7lueAZH51mbmb
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

tr_dp = '/content/drive/MyDrive/ML/mnist_train.csv'
ts_dp = '/content/drive/MyDrive/ML/mnist_test.csv'

d_tr = pd.read_csv(tr_dp)
d_ts = pd.read_csv(ts_dp)

print(" Here is the sample data for both the datasets (training and testing )")
print("\n TRAINING DATA SET\n")
print(d_tr.head(10))
print("\n TEST DATA SET\n")
print(d_ts.head(10))

import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize = (10,8))
sns.countplot(x = 'label', data = d_tr)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize = (10,8))
sns.countplot(x = 'label', data = d_ts)
plt.show()

d_tr= d_tr.drop(columns=['label'])
d_tr.describe()

corr_mat = d_tr.corr()
plt.figure(figsize = (10,8))
sns.heatmap(corr_mat, cmap = 'Accent', center = 0)

# Here we are converting the dataframes into the  numpy arrays
# for the process of clustering (so as to store image in a single 1D array)
d_tr = pd.read_csv(tr_dp)
X = d_tr.values
# As we have labels, so we will remove the first column of our dataset X
X = X[:, 1:]

# In order to achieve the better results, lets normalize the data we have,
 # Normalizing the data points so that they fall in the range [0,1]
n_cpt = int(input("Please enter the desired number of principal components you want in PCA:- "))
k_clust = int(input("Please enter the desired number of clusters you want after PCA:- "))

print(X)
print(np.shape(X))

# Perform Singular Value Decomposition of the calculated Covariance Matrix
# Here we are using the library for this purpose
from scipy.linalg import svd
U, sing_val, V_trans = svd(X, full_matrices = False)
#Getting the singular values
print(sing_val)
#Designing the singular value Matrix
sing_val_mat = np.diag(sing_val)
print(sing_val_mat)

sing_val_mat1 = sing_val_mat[0:n_cpt,:n_cpt]
U = U[:,:n_cpt]
V_trans=V_trans[:n_cpt,:]

# Now projecting the given data in matrix X onto the new space of reduced dimensionality
reduced_X = np.dot(U, sing_val_mat1)
org_X = np.dot(reduced_X,V_trans)
print("Therefore we have the projected data points onto a new sample space:-\n", reduced_X)
print("\n The shape of projected data matrix onto new feature space is:- ",np.shape(reduced_X))

# In this section, we are trying to visualise the images after performing PCA
import matplotlib.pyplot as plt
num_img, num_img_in_row = 10,5
num_row = (num_img + num_img_in_row - 1) // num_img_in_row
fig = plt.figure(figsize = (10,10))
for i in range(num_img):
    image = org_X[i].reshape(28,28)
    ax= fig.add_subplot(num_row,num_img_in_row, i+1)
    ax.imshow(image, cmap='gray')
    ax.axis("off")
plt.subplots_adjust(wspace=0.2, hspace=0.2)
plt.show()

# Now we will do Gaussian Mixture Models using inbuilt library
from sklearn.mixture import GaussianMixture as GM
mixing_gm = GM(n_components = k_clust) #Applying GMM Method in this step
mixing_gm.fit(reduced_X)
clasfn = mixing_gm.predict(reduced_X)

#Now after performing PCA and GMM, lets visualise how the cluster are looking now
print(f"For {n_cpt} number of components in PCA and {k_clust} number of clusters we have:- " )
import matplotlib.pyplot as plt
plt.figure(figsize = (10,8))
for i in range(k_clust):
    images_of_cluster = org_X[clasfn == i]
    for j in range(min(10,images_of_cluster.shape[0])):
      plt.subplot(k_clust,10,i*10+j+1)
      plt.imshow(images_of_cluster[0].reshape(28,28),cmap="gray")
      plt.axis("off")
plt.subplots_adjust(wspace=0.2, hspace=0.2)
plt.show()